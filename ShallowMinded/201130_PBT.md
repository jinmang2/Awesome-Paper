# [**Population Based Training of Neural Networks**](https://arxiv.org/abs/1711.09846)

[이전으로](https://github.com/jinmang2/Awesome-Papers/tree/master/ShallowMinded)

## Information
- Authors: 
  - `Max Jaderberg`
- Further Reading:
  - `Deep Learning`
  - `Deep Reinforcement Learning`
  - `Distributed Systems`
  - `Meta-Learning`
  - `Optimisation`
  - `Reinforcement Learning`

## Blog Post 정리
- NN이 비록 Go와 Atari 등 이미지 인식과 언어 번역에서 큰 성공을 거뒀지만 데이터에 맞는 네트워크 고르기 및 학습시키는 방법에 대해 간과하는 경우가 많음
- 현재까진 Hyperparameters는 경험, 임의 탐색 혹은 계산집약적인 검색 과정을 통해 골라졌으나 본 논문에서 각 task에 맞는 모델과 최상의 초모수 셋을 빠르게 찾는 방법론 PBT(Population Based Training)을 소개한다.
- 위 방법은 hyperparameter optimisation을 위해 흔히 사용되는 아래 두 방법론의 hybrid이다.
  - `Random Search`; NN의 모수는 병렬 독립적으로 학습되며 학습 과정에서 최상의 성과를 거둔 모델이 선택된다. (wasting computer resources)
  <img src="https://lh3.googleusercontent.com/TKQMhWxTTj4w7j_SwCG2pS532-4ZNBq3fLNIvdVmf8Ke87NWmR810Lqoht2eHn4Oj8hW13WJ4uCAAXOxNd2_GWeUClecRBFZp3KI=w1440-rw-v1" width=50% height=50%>
  
  - `Hand-tuning`; 연구자들이 최상의 hyperparameter를 예측, 모델에 사용하고 성과를 평가한다. (연구자가 happy할 때 까지 :))
    - 오랜 시간이 걸리고 완벽한 set-up을 위해 수개월이 걸릴 수 있기 때문에 bayesian optimisation과 같은 자동화 process를 사용한다.
    - 그래도 많은 시간이 걸린다.
  <img src="https://lh3.googleusercontent.com/2AIq0yYUkkCZnvMHn-dpUKmdmwlKnryRYmDzvD4iGlKUq36RrPqxWV9fP40OQZg7Rsxk5HucDsYMHvwXrnJw-q15ILSnYueRydLI1g=w1440-rw-v1" width=50% height=50%>
  
- `PBT`는 아래 절차로 학습한다.
  - `Random Search`와 같이 병렬적으로 학습
  - 그러나, **독립적**으로 학습시키지 않고 모집단의 멤버 worker가 다른 worker의 performance를 exploit하여 모집단의 남은 정보를 활용할 수 있다.
  - 이 후 현재 값을 임의로 바꿔 새로운 hyperparameter를 탐색한다.
  - exploting과 exploring은 주기적으로 수행한다.
  <img src="https://lh3.googleusercontent.com/7-FSSFPLz2ZTba8dyqd27T9sw7jNgrteex0s27ibOUqmxL7_k1QPzrOeLsZssNqVhiZhKpHtpD6f19PPoIN6qoVXVRDFbgEElN-Ix_k=w1440-rw-v1" width=50% height=50%>
  
- 위 과정을 통해
  - PBT가 좋은 hyperparameter를 빠르게 활용하고
  - 유망한 모델에 더 많은 훈련 시간을 할애할 수 있으며
  - 훈련 전반에 걸쳐 hyperparameter 값을 조정하여 최상의 구성을 자동으로 학습할 수 있다
- DM Lab, Atari, StarCraft2, Machine Translation, GAN 등에서 이전 SOTA score를 갱신

![pbt algorithm](https://user-images.githubusercontent.com/37775784/100559209-fd6b2a80-32f4-11eb-8cd2-cd5e33072c33.PNG)


## Comments
저도 흥미롭게 읽었습니다!!

최근 CS330 공부하면서 Meta에 아주 조금씩 발 담구고 있는데, (너무 어려워요...)Hyperparameter optimization도 meta-learning으로 아래와 같이 cast할 수 있단 말이 본 논문보면서 좀 더 많이 와닿았던 것 같아요!!
- hyperparameter h: Meta Parameter
- Model weight θ: Task-Specific Parameter

몇 가지 구현체도 같이 살펴봤는데,

- Tensor 구현체
  - https://github.com/angusfung/population-based-training
  - 논문의 Figure 2의 surrogate function Q_hat=1.2-h1 w1^2 - h2 w2^2가 주어졌을 때 간단한 quadratic function Q(θ)=1.2-w1^2-w2^2를 최대화하는 문제를 품
  - h: hyperparameter
  - w: model weight

- Pytorch 구현체
  - https://github.com/MattKleinsmith/pbt
  - https://github.com/voiler/PopulationBasedTraining(위 코드 repo를 따온 것으로 보이나 더 직관적으로 코드를 작성)
  - MNist를 ConvNet으로 품
  - lr, momentum이 hyperparameter
  - model weight가 task-specific parameter θ

DeepMind의 공식 구현체는 지금 잠깐 시간할애했을 때는 보이지 않더라구요... 논문에서도 기계번역 task에 적용헀을 때 Tensor2Tensor 라이브러리를 활용했다 라는 정보밖에 없어서 아쉬웠고 동희님 말씀대로 한번 페이퍼 정독하고 싶은 포스팅이었습니다

잘봤습니다 ㅎㅎ
